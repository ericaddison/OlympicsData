{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get seeds to use for the athlete crawler\n",
    "# get the features athletes for every sport\n",
    "# and get the first few athletes listed on every games page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib2\n",
    "import re\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load all the sports\n",
    "with open('./SportsTable.json') as data_file:\n",
    "    sportsTable = json.load(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsing results for boxing\n",
      "parsing results for golf\n",
      "Problem with golf\n",
      "'NoneType' object has no attribute 'find_all'\n",
      "parsing results for curling\n",
      "parsing results for snowboard\n",
      "parsing results for badminton\n",
      "parsing results for volleyball\n",
      "parsing results for handball\n",
      "parsing results for diving\n",
      "parsing results for shooting\n",
      "parsing results for skeleton\n",
      "parsing results for gymnastics-artistic\n",
      "parsing results for taekwondo\n",
      "parsing results for triathlon\n",
      "parsing results for basketball\n",
      "parsing results for equestrian-jumping\n",
      "parsing results for table-tennis\n",
      "parsing results for fencing\n",
      "parsing results for canoe-sprint\n",
      "parsing results for short-track-speed-skating\n",
      "parsing results for bobsleigh\n",
      "parsing results for ice-hockey\n",
      "parsing results for cycling-road\n",
      "parsing results for modern-pentathlon\n",
      "parsing results for hockey\n",
      "Problem with hockey\n",
      "'NoneType' object has no attribute 'find_all'\n",
      "parsing results for nordic-combined\n",
      "parsing results for synchronized-swimming\n",
      "parsing results for equestrian-dressage\n",
      "parsing results for freestyle-skiing\n",
      "parsing results for trampoline\n",
      "parsing results for cycling-bmx\n",
      "parsing results for cross-country-skiing\n",
      "parsing results for gymnastics-rhythmic\n",
      "parsing results for tennis\n",
      "parsing results for alpine-skiing\n",
      "parsing results for football\n",
      "parsing results for ski-jumping\n",
      "parsing results for wrestling-freestyle\n",
      "parsing results for equestrian-eventing\n",
      "parsing results for weightlifting\n",
      "parsing results for rugby\n",
      "Problem with rugby\n",
      "'NoneType' object has no attribute 'find_all'\n",
      "parsing results for speed-skating\n",
      "parsing results for beach-volleyball\n",
      "parsing results for archery\n",
      "parsing results for judo\n",
      "parsing results for canoe-slalom\n",
      "parsing results for sailing\n",
      "parsing results for rowing\n",
      "parsing results for cycling-track\n",
      "parsing results for wrestling-greco-roman\n",
      "parsing results for figure-skating\n",
      "parsing results for biathlon\n",
      "parsing results for cycling-mountain-bike\n",
      "parsing results for water-polo\n",
      "Problem with water-polo\n",
      "'NoneType' object has no attribute 'find_all'\n",
      "parsing results for athletics\n",
      "parsing results for luge\n",
      "parsing results for swimming\n"
     ]
    }
   ],
   "source": [
    "# go through every sport and get the featured athletes\n",
    "# base url for olympics site\n",
    "baseUrl = \"https://www.olympic.org\"\n",
    "\n",
    "# initialize resultsLinks dict\n",
    "featuredAthletes = set()\n",
    "\n",
    "# loop through sports\n",
    "for sport in sportsTable:\n",
    "    try:\n",
    "        sys.stdout.write(\"parsing results for \" + sport + \"\\n\")\n",
    "\n",
    "        # get the html\n",
    "        html = urllib2.urlopen(baseUrl+\"/\"+sport).read()\n",
    "\n",
    "        # soup it up\n",
    "        sportSoup = BeautifulSoup(html)\n",
    "\n",
    "        # get the list of related athletes\n",
    "        relatedList = sportSoup.find(\"ul\",class_=re.compile(\"related-list.*\"))\n",
    "        relatedTags = relatedList.find_all(\"a\",itemprop=\"url\")\n",
    "        for tag in relatedTags:\n",
    "            featuredAthletes.add(tag['href'])\n",
    "    except Exception as err:\n",
    "        print \"Problem with \" + sport\n",
    "        print format(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# need to get an athlete for golf, hockey, rugby, and water polo\n",
    "\n",
    "# rubgy will be tougher ... don't have related athletes section\n",
    "# same with hockey! Might need to steal from databaseolympics for these\n",
    "# might be true for all the team sports... same for football and basketball!\n",
    "# might need to parse sport pages for these (or databaseolympics)...\n",
    "\n",
    "featuredAthletes.add(\"/francis-newton\")   # one for golf men\n",
    "featuredAthletes.add(\"/daria-pratt\")      # one for golf women\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load all the sports\n",
    "with open('./OlympicsTable.json') as data_file:\n",
    "    olympicsTable = json.load(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsing results for beijing-2008\n",
      "parsing results for london-1908\n",
      "parsing results for nanjing-2014\n",
      "Problem with nanjing-2014\n",
      "'NoneType' object has no attribute 'find_all'\n",
      "parsing results for lillehammer-1994\n",
      "parsing results for chamonix-1924\n",
      "parsing results for tokyo-2020\n",
      "Problem with tokyo-2020\n",
      "'NoneType' object has no attribute 'find_all'\n",
      "parsing results for buenos-aires-2018\n",
      "Problem with buenos-aires-2018\n",
      "'NoneType' object has no attribute 'find_all'\n",
      "parsing results for seoul-1988\n",
      "parsing results for london-1948\n",
      "parsing results for innsbruck-1976\n",
      "parsing results for rio-2016\n",
      "Problem with rio-2016\n",
      "'NoneType' object has no attribute 'find_all'\n",
      "parsing results for beijing-2022\n",
      "Problem with beijing-2022\n",
      "'NoneType' object has no attribute 'find_all'\n",
      "parsing results for sapporo-1972\n",
      "parsing results for grenoble-1968\n",
      "parsing results for london-2012\n",
      "parsing results for albertville-1992\n",
      "parsing results for athens-1896\n",
      "parsing results for lillehammer-2016\n",
      "Problem with lillehammer-2016\n",
      "'NoneType' object has no attribute 'find_all'\n",
      "parsing results for innsbruck-2012\n",
      "Problem with innsbruck-2012\n",
      "'NoneType' object has no attribute 'find_all'\n",
      "parsing results for oslo-1952\n",
      "parsing results for sarajevo-1984\n",
      "parsing results for sydney-2000\n",
      "parsing results for rome-1960\n",
      "parsing results for montreal-1976\n",
      "parsing results for lake-placid-1980\n",
      "parsing results for st-moritz-1948\n",
      "parsing results for cortina-d-ampezzo-1956\n",
      "parsing results for mexico-1968\n",
      "parsing results for st-moritz-1928\n",
      "parsing results for melbourne-stockholm-1956\n",
      "parsing results for nagano-1998\n",
      "parsing results for lausanne-2020\n",
      "Problem with lausanne-2020\n",
      "'NoneType' object has no attribute 'find_all'\n",
      "parsing results for garmisch-partenkirchen-1936\n",
      "parsing results for atlanta-1996\n",
      "parsing results for vancouver-2010\n",
      "parsing results for pyeongchang-2018\n",
      "Problem with pyeongchang-2018\n",
      "'NoneType' object has no attribute 'find_all'\n",
      "parsing results for innsbruck-1964\n",
      "parsing results for amsterdam-1928\n",
      "parsing results for turin-2006\n",
      "parsing results for paris-1924\n",
      "parsing results for antwerp-1920\n",
      "parsing results for berlin-1936\n",
      "parsing results for singapore-2010\n",
      "Problem with singapore-2010\n",
      "'NoneType' object has no attribute 'find_all'\n",
      "parsing results for lake-placid-1932\n",
      "parsing results for los-angeles-1984\n",
      "parsing results for paris-1900\n",
      "parsing results for st-louis-1904\n",
      "parsing results for stockholm-1912\n",
      "parsing results for sochi-2014\n",
      "parsing results for barcelona-1992\n",
      "parsing results for los-angeles-1932\n",
      "parsing results for athens-2004\n",
      "parsing results for salt-lake-city-2002\n",
      "parsing results for munich-1972\n",
      "parsing results for calgary-1988\n",
      "parsing results for tokyo-1964\n",
      "parsing results for moscow-1980\n",
      "parsing results for squaw-valley-1960\n",
      "parsing results for helsinki-1952\n"
     ]
    }
   ],
   "source": [
    "# now parse all games pages for featured athletes to seed by time\n",
    "# go through every sport and get the featured athletes\n",
    "# base url for olympics site\n",
    "baseUrl = \"https://www.olympic.org\"\n",
    "\n",
    "# loop through games\n",
    "for olympics in olympicsTable:\n",
    "    try:\n",
    "        sys.stdout.write(\"parsing results for \" + olympics + \"\\n\")\n",
    "\n",
    "        # get the html\n",
    "        html = urllib2.urlopen(baseUrl+\"/\"+olympics).read()\n",
    "\n",
    "        # soup it up\n",
    "        olympicsSoup = BeautifulSoup(html)\n",
    "\n",
    "        # get the list of related athletes\n",
    "        relatedList = olympicsSoup.find(\"section\", class_=\"results ajax-area\")\n",
    "        relatedTags = relatedList.find_all(\"a\")\n",
    "        for tag in relatedTags:\n",
    "            if not re.match(re.compile(\"/ajaxscript.*\"),tag['href']):\n",
    "                featuredAthletes.add(tag['href'])\n",
    "    except Exception as err:\n",
    "        print \"Problem with \" + olympics\n",
    "        print format(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# output list of seed athletes\n",
    "athleteList = {}\n",
    "for ath in featuredAthletes:\n",
    "    athleteList[ath] = {}\n",
    "with open('./AthleteSeeds.dat','w') as outfile:\n",
    "    json.dump(athleteList, outfile, indent=4, sort_keys=True, separators=(',', ':'))\n",
    "    outfile.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
