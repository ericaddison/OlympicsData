{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get seeds to use for the athlete crawler\n",
    "# get the features athletes for every sport\n",
    "# and get the first few athletes listed on every games page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib2\n",
    "import re\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load all the sports\n",
    "with open('./SportsTable.json') as data_file:\n",
    "    sportsTable = json.load(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsing results for boxing\n",
      "parsing results for golf\n",
      "Problem with golf\n",
      "'NoneType' object has no attribute 'find_all'\n",
      "parsing results for curling\n",
      "parsing results for snowboard\n",
      "parsing results for badminton\n",
      "parsing results for volleyball\n",
      "parsing results for handball\n",
      "parsing results for diving\n",
      "parsing results for shooting\n",
      "parsing results for skeleton\n",
      "parsing results for gymnastics-artistic\n",
      "parsing results for taekwondo\n",
      "parsing results for triathlon\n",
      "parsing results for basketball\n",
      "parsing results for equestrian-jumping\n",
      "parsing results for table-tennis\n",
      "parsing results for fencing\n",
      "parsing results for canoe-sprint\n",
      "parsing results for short-track-speed-skating\n",
      "parsing results for bobsleigh\n",
      "parsing results for ice-hockey\n",
      "parsing results for cycling-road\n",
      "parsing results for modern-pentathlon\n",
      "parsing results for hockey\n",
      "Problem with hockey\n",
      "'NoneType' object has no attribute 'find_all'\n",
      "parsing results for nordic-combined\n",
      "parsing results for synchronized-swimming\n",
      "parsing results for equestrian-dressage\n",
      "parsing results for freestyle-skiing\n",
      "parsing results for trampoline\n",
      "parsing results for cycling-bmx\n",
      "parsing results for cross-country-skiing\n",
      "parsing results for gymnastics-rhythmic\n",
      "parsing results for tennis\n",
      "parsing results for alpine-skiing\n",
      "parsing results for football\n",
      "parsing results for ski-jumping\n",
      "parsing results for wrestling-freestyle\n",
      "parsing results for equestrian-eventing\n",
      "parsing results for weightlifting\n",
      "parsing results for rugby\n",
      "Problem with rugby\n",
      "'NoneType' object has no attribute 'find_all'\n",
      "parsing results for speed-skating\n",
      "parsing results for beach-volleyball\n",
      "parsing results for archery\n",
      "parsing results for judo\n",
      "parsing results for canoe-slalom\n",
      "parsing results for sailing\n",
      "parsing results for rowing\n",
      "parsing results for cycling-track\n",
      "parsing results for wrestling-greco-roman\n",
      "parsing results for figure-skating\n",
      "parsing results for biathlon\n",
      "parsing results for cycling-mountain-bike\n",
      "parsing results for water-polo\n",
      "Problem with water-polo\n",
      "'NoneType' object has no attribute 'find_all'\n",
      "parsing results for athletics\n",
      "parsing results for luge\n",
      "parsing results for swimming\n"
     ]
    }
   ],
   "source": [
    "# go through every sport and get the featured athletes\n",
    "# base url for olympics site\n",
    "baseUrl = \"https://www.olympic.org\"\n",
    "\n",
    "# initialize resultsLinks dict\n",
    "featuredAthletes = set()\n",
    "\n",
    "# loop through sports\n",
    "for sport in sportsTable:\n",
    "    try:\n",
    "        sys.stdout.write(\"parsing results for \" + sport + \"\\n\")\n",
    "\n",
    "        # get the html\n",
    "        html = urllib2.urlopen(baseUrl+\"/\"+sport).read()\n",
    "\n",
    "        # soup it up\n",
    "        sportSoup = BeautifulSoup(html)\n",
    "\n",
    "        # get the list of related athletes\n",
    "        relatedList = sportSoup.find(\"ul\",class_=re.compile(\"related-list.*\"))\n",
    "        relatedTags = relatedList.find_all(\"a\",itemprop=\"url\")\n",
    "        for tag in relatedTags:\n",
    "            featuredAthletes.add(tag['href'])\n",
    "    except Exception as err:\n",
    "        print \"Problem with \" + sport\n",
    "        print format(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# need to get an athlete for golf, hockey, rugby, and water polo\n",
    "\n",
    "# rubgy will be tougher ... don't have related athletes section\n",
    "# same with hockey! Might need to steal from databaseolympics for these\n",
    "# might be true for all the team sports... same for football and basketball!\n",
    "# might need to parse sport pages for these (or databaseolympics)...\n",
    "\n",
    "featuredAthletes.add(\"/francis-newton\")   # one for golf men\n",
    "featuredAthletes.add(\"/daria-pratt\")      # one for golf women\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load all the sports\n",
    "with open('./OlympicsTable.json') as data_file:\n",
    "    olympicsTable = json.load(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# now parse all games pages for featured athletes to seed by time\n",
    "# go through every sport and get the featured athletes\n",
    "# base url for olympics site\n",
    "baseUrl = \"https://www.olympic.org\"\n",
    "\n",
    "# loop through games\n",
    "for olympics in olympicsTable:\n",
    "    try:\n",
    "        sys.stdout.write(\"parsing results for \" + olympics + \"\\n\")\n",
    "\n",
    "        # get the html\n",
    "        html = urllib2.urlopen(baseUrl+\"/\"+olympics).read()\n",
    "\n",
    "        # soup it up\n",
    "        olympicsSoup = BeautifulSoup(html)\n",
    "\n",
    "        # get the list of related athletes\n",
    "        relatedList = olympicsSoup.find(\"section\", class_=\"results ajax-area\")\n",
    "        relatedTags = relatedList.find_all(\"a\")\n",
    "        for tag in relatedTags:\n",
    "            print tag['href']\n",
    "            #featuredAthletes.add(tag['href'])\n",
    "    except Exception as err:\n",
    "        print \"Problem with \" + olympics\n",
    "        print format(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
